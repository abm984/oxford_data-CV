{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_edbgXRw39nk"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import glob\n",
        "import tarfile\n",
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "from shutil import copyfile, rmtree\n",
        "import sys\n",
        "import json\n",
        "if sys.version_info[0] >= 3:\n",
        "    from urllib.request import urlretrieve\n",
        "else:\n",
        "    from urllib import urlretrieve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SgYjw6ci4LEc"
      },
      "outputs": [],
      "source": [
        "def download_file(url, dest=None):\n",
        "    if not dest:\n",
        "        dest = os.path.join(data_path, url.split('/')[-1])\n",
        "    urlretrieve(url, dest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "o80P7weW4PKL"
      },
      "outputs": [],
      "source": [
        "data_path = 'flower'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "T9gwdBDK4RRI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e42ef05-d764-4283-b575-85029d5b08c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading images...\n",
            "Downloading image labels...\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(data_path):\n",
        "    os.mkdir(data_path)\n",
        "flowers_archive_path = os.path.join(data_path, '102flowers.tgz')\n",
        "if not os.path.isfile(flowers_archive_path):\n",
        "    print ('Downloading images...')\n",
        "    download_file('http://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz')\n",
        "    tarfile.open(flowers_archive_path).extractall(path=data_path)\n",
        "\n",
        "image_labels_path = os.path.join(data_path, 'imagelabels.mat')\n",
        "if not os.path.isfile(image_labels_path):\n",
        "    print(\"Downloading image labels...\")\n",
        "    download_file('http://www.robots.ox.ac.uk/~vgg/data/flowers/102/imagelabels.mat')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Zltflmq54VJW"
      },
      "outputs": [],
      "source": [
        "image_labels = loadmat(image_labels_path)['labels'][0]\n",
        "image_labels -= 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5aqDesmb4YDn"
      },
      "outputs": [],
      "source": [
        "files = sorted(glob.glob(os.path.join(data_path, 'jpg', '*.jpg')))\n",
        "labels = np.array([i for i in zip(files, image_labels)])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j4ogpGyqDjst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RbIpt6bC4aQU"
      },
      "outputs": [],
      "source": [
        "cwd = os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zl89nlWI4cO_"
      },
      "outputs": [],
      "source": [
        "def move_files(dir_name,cwd,labels):\n",
        "    cur_dir_path = os.path.join(cwd, dir_name)\n",
        "    if not os.path.exists(cur_dir_path):\n",
        "        os.mkdir(cur_dir_path)\n",
        "    for i in range(0, 102):\n",
        "        class_dir = os.path.join(cwd, dir_name, str(i))\n",
        "        os.mkdir(class_dir)\n",
        "    for label in labels:\n",
        "        src = str(label[0])\n",
        "        dst = os.path.join(cwd,dir_name, label[1], src.split(os.sep)[-1])\n",
        "        copyfile(src, dst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "X0lcTNNV4ebm"
      },
      "outputs": [],
      "source": [
        "dir_name=os.path.join(data_path,'class')\n",
        "move_files(dir_name,cwd,labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_1Mud0kc4g3f"
      },
      "outputs": [],
      "source": [
        "def save_dict(content,filename):\n",
        "    content = dict(content)\n",
        "    with open(filename,'w') as file_object:\n",
        "        json.dump(content,file_object)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "r25ovX_74kLS"
      },
      "outputs": [],
      "source": [
        "def load_dict(filename):\n",
        "    with open(filename,'r') as file_object:\n",
        "        content = json.load(file_object)\n",
        "    return content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "FwkuEVDZ4mOQ"
      },
      "outputs": [],
      "source": [
        "save_dict(labels,os.path.join(data_path,'image-label.json'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Set the seed for reproducibility\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# Dataset directory\n",
        "dataset_directory = '/content/flower/class'\n",
        "\n",
        "# Split ratio\n",
        "train_ratio = 0.85\n",
        "\n",
        "# Load and preprocess the images\n",
        "image_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255.0,\n",
        "    validation_split=1 - train_ratio,\n",
        ")\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    dataset_directory,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        ")\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    dataset_directory,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        ")\n",
        "\n",
        "# Load pre-trained ResNet-50 model without top classification layers\n",
        "base_model = ResNet50(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(image_size[0], image_size[1], 3),\n",
        ")\n",
        "\n",
        "# Add custom classification layers\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "output = Dense(train_generator.num_classes, activation='softmax')(x)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "epochs = 10\n",
        "\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=len(validation_generator),\n",
        ")\n",
        "\n",
        "# Save the model (optional)\n",
        "model.save('/content/')\n",
        "\n",
        "# Evaluate the model on a test dataset (optional)\n",
        "#test_generator = datagen.flow_from_directory(\n",
        "#    '/path/to/test_dataset',\n",
        "#    target_size=image_size\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uelZipB4F7ja",
        "outputId": "e12a0c22-17a2-438f-9070-294331957071"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7004 images belonging to 102 classes.\n",
            "Found 1185 images belonging to 102 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 5s 0us/step\n",
            "Epoch 1/10\n",
            "219/219 [==============================] - 144s 428ms/step - loss: 1.8609 - accuracy: 0.5557 - val_loss: 98.2551 - val_accuracy: 0.0076\n",
            "Epoch 2/10\n",
            "219/219 [==============================] - 90s 410ms/step - loss: 0.5211 - accuracy: 0.8475 - val_loss: 12.4189 - val_accuracy: 0.0068\n",
            "Epoch 3/10\n",
            "219/219 [==============================] - 90s 411ms/step - loss: 0.2527 - accuracy: 0.9266 - val_loss: 8.1714 - val_accuracy: 0.0262\n",
            "Epoch 4/10\n",
            "219/219 [==============================] - 89s 407ms/step - loss: 0.2100 - accuracy: 0.9376 - val_loss: 3.4475 - val_accuracy: 0.3958\n",
            "Epoch 5/10\n",
            "219/219 [==============================] - 90s 408ms/step - loss: 0.1199 - accuracy: 0.9674 - val_loss: 1.2754 - val_accuracy: 0.6979\n",
            "Epoch 6/10\n",
            "219/219 [==============================] - 89s 406ms/step - loss: 0.1174 - accuracy: 0.9669 - val_loss: 1.0945 - val_accuracy: 0.7460\n",
            "Epoch 7/10\n",
            "219/219 [==============================] - 89s 406ms/step - loss: 0.1147 - accuracy: 0.9676 - val_loss: 0.7685 - val_accuracy: 0.7975\n",
            "Epoch 8/10\n",
            "219/219 [==============================] - 89s 406ms/step - loss: 0.0929 - accuracy: 0.9740 - val_loss: 1.6713 - val_accuracy: 0.6489\n",
            "Epoch 9/10\n",
            "219/219 [==============================] - 92s 419ms/step - loss: 0.0984 - accuracy: 0.9724 - val_loss: 1.1491 - val_accuracy: 0.7426\n",
            "Epoch 10/10\n",
            "219/219 [==============================] - 89s 406ms/step - loss: 0.0600 - accuracy: 0.9820 - val_loss: 1.2083 - val_accuracy: 0.7266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(os.path.join('model','model.h5'))"
      ],
      "metadata": {
        "id": "5a5JaKFHMJxT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_labels = [\n",
        "    'pink primrose',\n",
        "    'hard-leaved pocket orchid',\n",
        "    'canterbury bells',\n",
        "    'sweet pea',\n",
        "    'english marigold',\n",
        "    'tiger lily',\n",
        "    'moon orchid',\n",
        "    'bird of paradise',\n",
        "    'monkshood',\n",
        "    'globe thistle',\n",
        "    'snapdragon',\n",
        "    \"colt's foot\",\n",
        "    'king protea',\n",
        "    'spear thistle',\n",
        "    'yellow iris',\n",
        "    'globe-flower',\n",
        "    'purple coneflower',\n",
        "    'peruvian lily',\n",
        "    'balloon flower',\n",
        "    'giant white arum lily',\n",
        "    'fire lily',\n",
        "    'pincushion flower',\n",
        "    'fritillary',\n",
        "    'red ginger',\n",
        "    'grape hyacinth',\n",
        "    'corn poppy',\n",
        "    'prince of wales feathers',\n",
        "    'stemless gentian',\n",
        "    'artichoke',\n",
        "    'sweet william',\n",
        "    'carnation',\n",
        "    'garden phlox',\n",
        "    'love in the mist',\n",
        "    'mexican aster',\n",
        "    'alpine sea holly',\n",
        "    'ruby-lipped cattleya',\n",
        "    'cape flower',\n",
        "    'great masterwort',\n",
        "    'siam tulip',\n",
        "    'lenten rose',\n",
        "    'barbeton daisy',\n",
        "    'daffodil',\n",
        "    'sword lily',\n",
        "    'poinsettia',\n",
        "    'bolero deep blue',\n",
        "    'wallflower',\n",
        "    'marigold',\n",
        "    'buttercup',\n",
        "    'oxeye daisy',\n",
        "    'common dandelion',\n",
        "    'petunia',\n",
        "    'wild pansy',\n",
        "    'primula',\n",
        "    'sunflower',\n",
        "    'pelargonium',\n",
        "    'bishop of llandaff',\n",
        "    'gaura',\n",
        "    'geranium',\n",
        "    'orange dahlia',\n",
        "    'pink-yellow dahlia?',\n",
        "    'cautleya spicata',\n",
        "    'japanese anemone',\n",
        "    'black-eyed susan',\n",
        "    'silverbush',\n",
        "    'californian poppy',\n",
        "    'osteospermum',\n",
        "    'spring crocus',\n",
        "    'bearded iris',\n",
        "    'windflower',\n",
        "    'tree poppy',\n",
        "    'gazania',\n",
        "    'azalea',\n",
        "    'water lily',\n",
        "    'rose',\n",
        "    'thorn apple',\n",
        "    'morning glory',\n",
        "    'passion flower',\n",
        "    'lotus',\n",
        "    'toad lily',\n",
        "    'anthurium',\n",
        "    'frangipani',\n",
        "    'clematis',\n",
        "    'hibiscus',\n",
        "    'columbine',\n",
        "    'desert-rose',\n",
        "    'tree mallow',\n",
        "    'magnolia',\n",
        "    'cyclamen ',\n",
        "    'watercress',\n",
        "    'canna lily',\n",
        "    'hippeastrum ',\n",
        "    'bee balm',\n",
        "    'ball moss',\n",
        "    'foxglove',\n",
        "    'bougainvillea',\n",
        "    'camellia',\n",
        "    'mallow',\n",
        "    'mexican petunia',\n",
        "    'bromelia',\n",
        "    'blanket flower',\n",
        "    'trumpet creeper',\n",
        "    'blackberry lily'\n",
        "]"
      ],
      "metadata": {
        "id": "DNY7VHfMO7vM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the saved model\n",
        "model = load_model('/content/model/model.h5')\n",
        "\n",
        "# Directory containing the images for prediction\n",
        "images_directory = '/content/flower/class/1'\n",
        "\n",
        "# List the images in the directory\n",
        "image_files = os.listdir(images_directory)\n",
        "\n",
        "# Make predictions for each image\n",
        "for image_file in image_files:\n",
        "    # Load and preprocess the image\n",
        "    img_path = os.path.join(images_directory, image_file)\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    img = image.img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img /= 255.0  # Normalize the image\n",
        "\n",
        "    # Make prediction\n",
        "    predictions = model.predict(img)\n",
        "    predicted_class_index = np.argmax(predictions[0])\n",
        "\n",
        "    # Get the predicted class label\n",
        "    # Assuming you have a list of class labels used during training\n",
        "     # Update with your own labels\n",
        "    predicted_class_label = class_labels[predicted_class_index]\n",
        "\n",
        "    # Print the predicted class label\n",
        "    print(f\"Image: {image_file} | Predicted class: {predicted_class_label}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oB0dElEUOph-",
        "outputId": "d40ba33a-8942-48fd-ef12-e590edc6001d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "Image: image_05107.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Image: image_05134.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Image: image_05145.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Image: image_05130.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Image: image_05091.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Image: image_05137.jpg | Predicted class: ruby-lipped cattleya\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Image: image_05146.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Image: image_05104.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Image: image_05090.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Image: image_05098.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Image: image_05140.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Image: image_05097.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Image: image_05120.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Image: image_05144.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Image: image_05094.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Image: image_05143.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Image: image_05125.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Image: image_05117.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Image: image_05115.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Image: image_05131.jpg | Predicted class: pink primrose\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Image: image_05128.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Image: image_05124.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Image: image_05114.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Image: image_05103.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Image: image_05093.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Image: image_05126.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Image: image_05099.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Image: image_05089.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Image: image_05092.jpg | Predicted class: buttercup\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Image: image_05135.jpg | Predicted class: colt's foot\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Image: image_05141.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Image: image_05113.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "Image: image_05138.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "Image: image_05112.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "Image: image_05110.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Image: image_05132.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Image: image_05127.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "Image: image_05119.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Image: image_05116.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Image: image_05108.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "Image: image_05088.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "Image: image_05136.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "Image: image_05122.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "Image: image_05096.jpg | Predicted class: colt's foot\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "Image: image_05129.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "Image: image_05106.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Image: image_05139.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Image: image_05101.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Image: image_05123.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "Image: image_05133.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "Image: image_05121.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "Image: image_05087.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "Image: image_05105.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Image: image_05142.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Image: image_05100.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Image: image_05111.jpg | Predicted class: bromelia\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Image: image_05095.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Image: image_05109.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Image: image_05102.jpg | Predicted class: hard-leaved pocket orchid\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Image: image_05118.jpg | Predicted class: hard-leaved pocket orchid\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}